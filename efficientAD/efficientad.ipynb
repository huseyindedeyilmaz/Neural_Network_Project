{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\hy138\\Desktop\\neural_network_project\\Neural_Network_Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hy138\\\\Desktop\\\\neural_network_project\\\\Neural_Network_Project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientAD.efficientADModel import EfficientAD\n",
    "from common import Config\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_threshold_on_train(model, train_dir):\n",
    "    scores = []\n",
    "    for fname in os.listdir(train_dir):\n",
    "        if fname.endswith(('.png', '.jpg', '.tiff')):\n",
    "            img_path = os.path.join(train_dir, fname)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            score, _ = model.predict_one_image(img)\n",
    "            scores.append(score)\n",
    "    threshold = max(scores)\n",
    "    print(f\"Threshold (max anomaly score on train): {threshold:.4f}\")\n",
    "    return threshold\n",
    "\n",
    "def evaluate_on_test(model, test_good_dir, test_defect_dir, threshold):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for fname in os.listdir(test_good_dir):\n",
    "        if fname.endswith(('.png', '.jpg', '.tiff')):\n",
    "            img = Image.open(os.path.join(test_good_dir, fname)).convert('RGB')\n",
    "            score, _ = model.predict_one_image(img)\n",
    "            y_true.append(0)  \n",
    "            y_pred.append(1 if score > threshold else 0)\n",
    "\n",
    "        \n",
    "    for fname in os.listdir(test_defect_dir):\n",
    "        if fname.endswith(('.png', '.jpg', '.tiff')):\n",
    "            img = Image.open(os.path.join(test_defect_dir, fname)).convert('RGB')\n",
    "            score, _ = model.predict_one_image(img)\n",
    "            y_true.append(1)  \n",
    "            y_pred.append(1 if score > threshold else 0)\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    return f1, y_true, y_pred\n",
    "\n",
    "def calculateIoU(gtMask, predMask):\n",
    "    tp = np.logical_and(gtMask == 1, predMask == 1).sum()\n",
    "    fp = np.logical_and(gtMask == 0, predMask == 1).sum()\n",
    "    fn = np.logical_and(gtMask == 1, predMask == 0).sum()\n",
    "\n",
    "    denominator = tp + fp + fn\n",
    "    if denominator == 0:\n",
    "        return 1.0  \n",
    "    return tp / denominator\n",
    "\n",
    "\n",
    "def evaluate_iou(model, defect_dir, gt_dir, threshold_segmentation):\n",
    "    iou_scores = []\n",
    "    \n",
    "    defect_fnames = sorted(os.listdir(defect_dir))\n",
    "    gt_fnames = sorted(os.listdir(gt_dir))\n",
    "    \n",
    "    for defect_fname, gt_fname in zip(defect_fnames, gt_fnames):\n",
    "        if defect_fname.endswith(('.png', '.jpg', '.tiff')):\n",
    "            img_path = os.path.join(defect_dir, defect_fname)\n",
    "            gt_path = os.path.join(gt_dir, gt_fname)\n",
    "            \n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            _, heatmap = model.predict_one_image(img)\n",
    "            \n",
    "            binary_mask = (heatmap > threshold_segmentation).astype(np.uint8)\n",
    "            \n",
    "            gt_mask = np.array(Image.open(gt_path).convert('L'))\n",
    "            gt_mask = (gt_mask > 127).astype(np.uint8)  # GT mask binarize ediliyor\n",
    "            \n",
    "            iou = calculateIoU(gt_mask, binary_mask)\n",
    "            iou_scores.append(iou)\n",
    "    \n",
    "    mean_iou = np.mean(iou_scores)\n",
    "    print(f\"Mean IoU Score: {mean_iou:.4f}\")\n",
    "    return mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hy138\\Desktop\\neural_network_project\\Neural_Network_Project\\efficientAD\\efficientADModel.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(self.config.weights, map_location='cpu'))\n",
      "Computing mean of features: 100%|██████████| 63/63 [00:05<00:00, 10.86it/s]\n",
      "Computing std of features: 100%|██████████| 63/63 [00:05<00:00, 11.70it/s]\n",
      "Current loss: 16.0197:   0%|          | 31/10000 [00:04<26:07,  6.36it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m Config(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/efficientad\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataset_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./wood_dataset/wood/train/\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m EfficientAD(config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\neural_network_project\\Neural_Network_Project\\efficientAD\\efficientADModel.py:154\u001b[0m, in \u001b[0;36mEfficientAD.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    153\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 154\u001b[0m final_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss_total\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iteration \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    157\u001b[0m     tqdm_obj\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_total\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = Config(model_name=\"model\", output_dir = \"./models/efficientad\", dataset_path=\"./wood_dataset/wood/train/\", train_steps=10000)\n",
    "\n",
    "model = EfficientAD(config=config)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hy138\\Desktop\\neural_network_project\\Neural_Network_Project\\efficientAD\\efficientADModel.py:390: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pth_file = torch.load(self.config.pretrain_model_path)\n"
     ]
    }
   ],
   "source": [
    "config = Config(model_name=\"model\", pretrain_model_path= \"./models/efficientad/model/model.pth\")\n",
    "\n",
    "model = EfficientAD(config=config)\n",
    "model.initialize_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold (max anomaly score on train): 0.2425\n"
     ]
    }
   ],
   "source": [
    "threshold = compute_threshold_on_train(model, \"./wood_dataset/wood/train/good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9064748201438849,\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_on_test(model, \"./wood_dataset/wood/test/good\", \"./wood_dataset/wood/test/defect\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU Score: 0.1893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1892950111361436"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_iou(model, \"./wood_dataset/wood/test/defect\", \"./wood_dataset/wood/ground_truth/defect\",threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
